# 敏感词检查
1. 使用伯努利贝叶斯算法
2. 基于python3.6 & sklearn


### 思考问题

1. 样本集问题导致存在数据倾斜,补足数据or考虑补集贝叶斯?
2. 样本过大时构建词袋内存不够,需要引入HashingVectorizer
3. 打分过低(80以下),需要排查下


### 2020-05-15

1. 尝试引入MultiLabelBinarizer处理特征,效果不佳
2. 加大词汇样本,去除纯数字后,打分飙升(96+)
3. 依然后肉眼可见的敏感词没有被识别出来(猜测还是样本问题?)
4. 是否需要拆分训练组和测试组？